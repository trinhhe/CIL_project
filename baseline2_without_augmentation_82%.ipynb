{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "buNjnKnodgB4",
        "outputId": "8a7353f7-d788-4769-c67b-1e52e5d44f2a"
      },
      "source": [
        "from sklearn import linear_model\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os,sys\n",
        "from PIL import Image\n",
        "\n",
        "# importing the libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# for reading and displaying images\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# for creating validation set\n",
        "from sklearn.model_selection import train_test_split\n",
        "# for evaluating the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# PyTorch libraries and modules\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "\"\"\"\n",
        "    To execute the code run the following command\n",
        "        python baseline2.py\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n    To execute the code run the following command\\n        python baseline2.py\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS8mxDYBiZEU"
      },
      "source": [
        "import torch\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKvrQlJAlVgj",
        "outputId": "7c69d300-5da7-4a72-9db1-2995012884e6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtP2-aXujkLD",
        "outputId": "ea46d699-92f7-41a5-a3df-7e19a29bfde2"
      },
      "source": [
        "\n",
        "root_dir = \"/content/drive/My Drive/CIL-project2021/Data/\"\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycTnS32ylY8i"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "#################################\n",
        "##### paths to google colab #####\n",
        "#################################\n",
        "base_DIR_training = root_dir + \"training/training/\"\n",
        "base_DIR_testing = root_dir + \"test_images/test_images/\"\n",
        "base_DIR_aug = root_dir + \"training_augmented/training_augmented/\"\n",
        "\n",
        "ground_truth_PATH_TRAIN = join(base_DIR_training , \"groundtruth\") \n",
        "images_PATH_TRAIN = join(base_DIR_training , \"images\")\n",
        "\n",
        "\n",
        "ground_truth_PATH_AUG = join(base_DIR_aug , \"groundtruth\") \n",
        "images_PATH_AUG = join(base_DIR_aug, \"images\")\n",
        "\n",
        "ROTATE = True\n",
        "TRANSLATE = True\n",
        "ADD_NOISE = True\n",
        "BLUR = True\n",
        "\n",
        "####################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiJBC5h9dgCB",
        "outputId": "f93a5179-7072-45e8-ab66-5bd74f793db5"
      },
      "source": [
        "import torch\n",
        "import torch\n",
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9781, 0.2566, 0.4616],\n",
            "        [0.9977, 0.6183, 0.6016],\n",
            "        [0.6096, 0.5995, 0.7252],\n",
            "        [0.6833, 0.5892, 0.8371],\n",
            "        [0.9938, 0.0723, 0.3763]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djLzVr7gdgCC"
      },
      "source": [
        "def load_image(infilename):\n",
        "    data = mpimg.imread(infilename)\n",
        "    return data\n",
        "def img_float_to_uint8(img):\n",
        "    rimg = img - np.min(img)\n",
        "    rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
        "    return rimg\n",
        "\n",
        "# Concatenate an image and its groundtruth\n",
        "def concatenate_images(img, gt_img):\n",
        "    nChannels = len(gt_img.shape)\n",
        "    w = gt_img.shape[0]\n",
        "    h = gt_img.shape[1]\n",
        "    if nChannels == 3:\n",
        "        cimg = np.concatenate((img, gt_img), axis=1)\n",
        "    else:\n",
        "        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
        "        gt_img8 = img_float_to_uint8(gt_img)\n",
        "        gt_img_3c[:,:,0] = gt_img8\n",
        "        gt_img_3c[:,:,1] = gt_img8\n",
        "        gt_img_3c[:,:,2] = gt_img8\n",
        "        img8 = img_float_to_uint8(img)\n",
        "        cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
        "    return cimg\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSQAZz7wdgCC"
      },
      "source": [
        "def img_crop(im, w, h):\n",
        "    list_patches = []\n",
        "    imgwidth = im.shape[0]\n",
        "    imgheight = im.shape[1]\n",
        "    is_2d = len(im.shape) < 3\n",
        "    for i in range(0,imgheight,h):\n",
        "        for j in range(0,imgwidth,w):\n",
        "            if is_2d:\n",
        "                im_patch = im[j:j+w, i:i+h]\n",
        "            else:\n",
        "                im_patch = im[j:j+w, i:i+h, :]\n",
        "            list_patches.append(im_patch)\n",
        "    return list_patches\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOeStS0wdgCD",
        "outputId": "c8a805a4-00ac-4803-d2f3-5b626080d331"
      },
      "source": [
        "files = os.listdir(ground_truth_PATH_TRAIN)\n",
        "n = len(files) # Load maximum 20 images\n",
        "print(\"Loading \" + str(n) + \" images\")\n",
        "imgs = [load_image(os.path.join(images_PATH_TRAIN, files[i])) for i in range(n) if files[i].endswith('.png')]\n",
        "\n",
        "#gt_dir = os.path.join(data_dir,  ground_truth_PATH_TRAIN)\n",
        "print(\"Loading \" + str(n) + \" images\")\n",
        "gt_imgs = [load_image(os.path.join(ground_truth_PATH_TRAIN, files[i])) for i in range(n) if files[i].endswith('.png')]\n",
        "print(files[0])\n",
        "\n",
        "n = 100 # Only use 10 images for training\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading 100 images\n",
            "Loading 100 images\n",
            "satImage_063.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swh0E8GgdgCD",
        "outputId": "69ea48b8-3463-4ae6-8d5a-7e8ebf1f127f"
      },
      "source": [
        "#print('Image size = ' + str(imgs[0].shape[0]) + ',' + str(imgs[0].shape[1]))\n",
        "# Extract patches from input images\n",
        "patch_size = 16 # each patch is 16*16 pixels\n",
        "\n",
        "img_patches = [img_crop(imgs[i], patch_size, patch_size) for i in range(n)]\n",
        "gt_patches = [img_crop(gt_imgs[i], patch_size, patch_size) for i in range(n)]\n",
        "\n",
        "\n",
        "print(\"img_patches: \", np.array(img_patches).shape )\n",
        "# Linearize list of patches\n",
        "img_patches = np.asarray([img_patches[i][j][:,:,0] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])\n",
        "print(\"img_patches: \", img_patches.shape)\n",
        "gt_patches =  np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "img_patches:  (100, 625, 16, 16, 3)\n",
            "img_patches:  (62500, 16, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6UBeFgJdgCE"
      },
      "source": [
        "# Extract 6-dimensional features consisting of average RGB color as well as variance\n",
        "def extract_features(img):\n",
        "    feat_m = np.mean(img, axis=(0,1))\n",
        "    feat_v = np.var(img, axis=(0,1))\n",
        "    feat = np.append(feat_m, feat_v)\n",
        "    return feat\n",
        "\n",
        "# Extract 2-dimensional features consisting of average gray color as well as variance\n",
        "def extract_features_2d(img):\n",
        "    #print(\"small image dim: \", img.shape)\n",
        "    feat_m = np.mean(img)\n",
        "    feat_v = np.var(img)\n",
        "    feat = np.append(feat_m, feat_v)\n",
        "    return feat\n",
        "\n",
        "# Extract features for a given image\n",
        "def extract_img_features(filename):\n",
        "    img = load_image(filename)\n",
        "    #print(\"img size: \", img.shape)\n",
        "    img_patches = img_crop(img, patch_size, patch_size)\n",
        "    X = np.asarray([(img_patches[i][:,:,0]) for i in range(len(img_patches))])\n",
        "    return X\n",
        "\n",
        "\n",
        "# Compute features for each image patch\n",
        "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRL149N3dgCE"
      },
      "source": [
        "def value_to_class(v):\n",
        "    df = np.sum(v)\n",
        "    #print(\"df: \", df)\n",
        "    if df > foreground_threshold:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "#X = np.asarray([extract_features_2d(img_patches[i]) for i in range(len(img_patches))])\n",
        "X = img_patches \n",
        "#print(\"the shape of X: \", X.shape)\n",
        "Y = np.asarray([value_to_class(np.mean(gt_patches[i])) for i in range(len(gt_patches))])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqBJSWAqdgCE",
        "outputId": "103049b3-45e5-4077-b154-6e40c0d9e357"
      },
      "source": [
        "X2= X.reshape(62500, 1, 16, 16)\n",
        "print(\"shape of X: \", X2.shape)\n",
        "\n",
        "print(\"shape of Y: \", Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of X:  (62500, 1, 16, 16)\n",
            "shape of Y:  (62500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx0oh3LcdgCF",
        "outputId": "ecf2a415-40a4-4050-ff7d-b63b8b8cc3ab"
      },
      "source": [
        "\n",
        "train_x  = torch.from_numpy(X2)\n",
        "\n",
        "# converting the target into torch format\n",
        "train_y =  Y.astype(int)\n",
        "train_y = torch.from_numpy(Y)\n",
        "train_x.shape, train_y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([62500, 1, 16, 16]), torch.Size([62500]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6MLZunRdgCG"
      },
      "source": [
        "class Net(Module):   \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.cnn_layers = Sequential(\n",
        "            # Defining a 2D convolution layer\n",
        "            Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n",
        "            BatchNorm2d(4),\n",
        "            ReLU(inplace=True),\n",
        "            MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Defining another 2D convolution layer\n",
        "            Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
        "            BatchNorm2d(4),\n",
        "            ReLU(inplace=True),\n",
        "            MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.linear_layers = Sequential(\n",
        "            Linear(64, 10)\n",
        "        )\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        print(x.size())\n",
        "        x = self.linear_layers(x)\n",
        "        return x\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IReygWEqdgCG",
        "outputId": "e1a301d4-9efc-46b9-cc80-4cd70c859390"
      },
      "source": [
        "model = Net()\n",
        "# defining the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=0.07)\n",
        "# defining the loss function\n",
        "criterion = CrossEntropyLoss()\n",
        "# checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "        \n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (cnn_layers): Sequential(\n",
            "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (linear_layers): Sequential(\n",
            "    (0): Linear(in_features=64, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1befFEFcdgCH"
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    tr_loss = 0\n",
        "    # getting the training set\n",
        "    x_train, y_train = Variable(train_x), Variable(train_y)\n",
        "    # getting the validation set\n",
        "    x_val, y_val = Variable(train_x), Variable(train_y)\n",
        "    # converting the data into GPU format\n",
        "    if torch.cuda.is_available():\n",
        "        x_train = x_train.cuda()\n",
        "        y_train = y_train.cuda()\n",
        "        x_val = x_val.cuda()\n",
        "        y_val = y_val.cuda()\n",
        "\n",
        "    # clearing the Gradients of the model parameters\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # prediction for training and validation set\n",
        "    output_train = model(x_train)\n",
        "    output_val = model(x_val)\n",
        "\n",
        "    # computing the training and validation loss\n",
        "    loss_train = criterion(output_train, y_train)\n",
        "    loss_val = criterion(output_val, y_val)\n",
        "    train_losses.append(loss_train)\n",
        "    val_losses.append(loss_val)\n",
        "\n",
        "    # computing the updated weights of all the model parameters\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "    tr_loss = loss_train.item()\n",
        "    if epoch%2 == 0:\n",
        "        # printing the validation loss\n",
        "        print('Epoch : ',epoch+1, '\\t', 'loss :', loss_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3puzRbQdgCH",
        "outputId": "16d5a226-e027-4ca0-e6a1-4ba6f90ecd88"
      },
      "source": [
        "# defining the number of epochs\n",
        "n_epochs = 5\n",
        "# empty list to store training losses\n",
        "train_losses = []\n",
        "# empty list to store validation losses\n",
        "val_losses = []\n",
        "# training the model\n",
        "for epoch in range(n_epochs):\n",
        "    train(epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([62500, 64])\n",
            "torch.Size([62500, 64])\n",
            "Epoch :  1 \t loss : tensor(2.5912, grad_fn=<NllLossBackward>)\n",
            "torch.Size([62500, 64])\n",
            "torch.Size([62500, 64])\n",
            "torch.Size([62500, 64])\n",
            "torch.Size([62500, 64])\n",
            "Epoch :  3 \t loss : tensor(0.5960, grad_fn=<NllLossBackward>)\n",
            "torch.Size([62500, 64])\n",
            "torch.Size([62500, 64])\n",
            "torch.Size([62500, 64])\n",
            "torch.Size([62500, 64])\n",
            "Epoch :  5 \t loss : tensor(0.5759, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79pAyTizdgCI",
        "outputId": "9a17991c-84be-451b-a856-f05414106756"
      },
      "source": [
        "# prediction for training set\n",
        "\n",
        "output = model(train_x)\n",
        "print(output.shape)\n",
        "    \n",
        "#softmax = torch.exp(output).cpu()\n",
        "#prob = list(softmax.numpy())\n",
        "\n",
        "m = Softmax(dim=1)\n",
        "out = m(output)\n",
        "print(\"out: \",out.shape)\n",
        "predictions = np.argmax(list(out.detach().numpy()), axis=1)\n",
        "\n",
        "\n",
        "# accuracy on training set\n",
        "accuracy_score(train_y, predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([62500, 64])\n",
            "torch.Size([62500, 10])\n",
            "out:  torch.Size([62500, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.73584"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1GNRBe8dgCI",
        "outputId": "b1640f76-67f7-48a2-9bb1-c5c81f297eb0"
      },
      "source": [
        "def prediction_to_file(idimg, res, submission_file):\n",
        "  predictions = res.reshape(38,38)\n",
        "  for j in range(0, predictions.shape[1]):\n",
        "    for i in range(0, predictions.shape[0]):\n",
        "      with open(submission_file, 'a') as f:\n",
        "        _id = '{:03d}'.format(idimg)\n",
        "        f.write(f'{_id}_{j*patch_size}_{i*patch_size},{predictions[i,j]}\\n')\n",
        "\n",
        "\n",
        "ids = [int(filename.split('_')[1].split('.')[0]) for filename in os.listdir(base_DIR_testing)]\n",
        "#print(\"ids: \", ids)\n",
        "ids.sort()\n",
        "submission_file = '/content/drive/My Drive/CIL-project2021/submission_baseline1.csv'\n",
        "try:\n",
        "  os.remove(submission_file)\n",
        "except OSError:\n",
        "  pass\n",
        "with open(submission_file, 'a') as f:\n",
        "  f.write('id,prediction\\n')\n",
        "\n",
        "print(\"predicting...\")\n",
        "for id in ids:\n",
        "  #for path in files:\n",
        "  Xtest = extract_img_features(f'{base_DIR_testing}/test_{id}.png')\n",
        "  print(Xtest.shape)\n",
        "  Xtest2= Xtest.reshape(1444,1, 16, 16)\n",
        "  test_x  = torch.from_numpy(Xtest2)\n",
        "  print(test_x.shape)\n",
        "\n",
        "  output_test = model(test_x)\n",
        "  m = Softmax(dim=1)\n",
        "  out_test = m(output_test)\n",
        "  print(\"out: \", out_test.shape)\n",
        "  predictions_test = np.argmax(list(out_test.detach().numpy()), axis=1)\n",
        "  #print(\"the shape of Xtest: \", Xtest.shape)\n",
        "  #print(\"the shape of res: \", res.shape)\n",
        "  #plt.scatter(Xtest[:, 0], Xtest[:, 1], c=res, edgecolors='k', cmap=plt.cm.Paired)\n",
        "  prediction_to_file(id, predictions_test, submission_file)\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicting...\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n",
            "(1444, 16, 16)\n",
            "torch.Size([1444, 1, 16, 16])\n",
            "torch.Size([1444, 64])\n",
            "out:  torch.Size([1444, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}